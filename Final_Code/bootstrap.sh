#!/usr/bin/env bash
# Shebangë¼ì¸, ìŠ¤í¬ë¦½íŠ¸ê°€ bashë¡œ ì‹¤í–‰ë˜ë„ë¡ ì§€ì •í•¨ 

PS1=${PS1-}
# PS1(í”„ë¡¬í”„íŠ¸ ë³€ìˆ˜)ì´ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°, ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”í•¨
set -euo pipefail
# ìŠ¤í¬ë¦½íŠ¸ì˜ ì•ˆì •ì„±ê³¼ ì˜¤ë¥˜ íƒì§€ë¥¼ ê°•í™”, ì˜ˆìƒì¹˜ ëª»í•œ ìƒí™©ì—ì„œ ìŠ¤í¬ë¦½íŠ¸ê°€ ì¤‘ë‹¨ë˜ë„ë¡ í•¨(-e: ëª…ë ¹ì–´ ì‹¤íŒ¨ ì‹œ ì¢…ë£Œ, -u: ì •ì˜ë˜ì§€ ì•Šì€ ë³€ìˆ˜ ì‚¬ìš© ì‹œ ì˜¤ë¥˜ ë°œìƒ, -o pipefail: íŒŒì´í”„ë¼ì¸ ë‚´ ëª…ë ¹ì–´ ì‹¤íŒ¨ ì‹œ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨ë¡œ ê°„ì£¼)

# --- locate aws cli across MSYS2 / Windows ---
AWS_CLI_BIN="${AWS_CLI_BIN-}"  # allow override from env
# ê¸°ì¡´ì— ì„¤ì •ëœ AWS_CLI_BIN í™˜ê²½ ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ê±°ë‚˜, ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”í•¨
if [ -z "${AWS_CLI_BIN}" ]; then # AWS_CLI_BINì´ ë¹„ì–´ìˆê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì€ ê²½ìš°; -z ì˜µì…˜: ë³€ìˆ˜ê°€ ë¹„ì–´ìˆê±°ë‚˜, ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° true ë°˜í™˜
  if command -v aws >/dev/null 2>&1; then # aws ëª…ë ¹ì–´ê°€ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•¨; command -v: ëª…ë ¹ì–´ì˜ ê²½ë¡œë¥¼ ì¶œë ¥í•¨, >/dev/null 2>&1: í‘œì¤€ ì¶œë ¥ê³¼ í‘œì¤€ ì˜¤ë¥˜ë¥¼ ëª¨ë‘ ë²„ë¦¼
    AWS_CLI_BIN="aws"
  elif [ -x "/c/Program Files/Amazon/AWSCLIV2/aws.exe" ]; then # Windowsì˜ ê¸°ë³¸ ì„¤ì¹˜ ê²½ë¡œì— AWS CLIê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸í•¨; -x ì˜µì…˜: íŒŒì¼ì´ ì¡´ì¬í•˜ê³ , ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ìš° true ë°˜í™˜
    AWS_CLI_BIN="/c/Program Files/Amazon/AWSCLIV2/aws.exe"
  elif [ -x "/c/Program Files/Amazon/AWSCLI/aws.exe" ]; then
    AWS_CLI_BIN="/c/Program Files/Amazon/AWSCLI/aws.exe"
  else
    echo "âŒ Cannot find AWS CLI. Install it or set AWS_CLI_BIN to full path (e.g. /c/Program Files/Amazon/AWSCLIV2/aws.exe)" >&2
    exit 1
  fi
fi
AWS_CLI="$AWS_CLI_BIN"
# --- end locate aws cli ---

# ë¡œê·¸ íŒŒì¼ (ì›í•˜ëŠ” ê²½ë¡œë¡œ ë°”ê¿”ë„ ë¨)
LOG_DIR="${LOG_DIR:-./logs}"
mkdir -p "$LOG_DIR"
LOG_FILE="${LOG_FILE:-$LOG_DIR/bootstrap_$(date +%Y%m%d_%H%M%S).log}"

# â”€â”€ ì—ëŸ¬ íŠ¸ë©: ì‹¤íŒ¨ ë¼ì¸/ëª…ë ¹/ë¦¬í„´ì½”ë“œ ì¶œë ¥ + ì…¸ ìœ ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
trap 'rc=$?; echo; echo "âŒ ERROR: line $LINENO while running: $BASH_COMMAND (exit=$rc)"; \
      echo "ğŸ‘‰ Full log: $LOG_FILE"; \
      echo "Dropping you into interactive shell (type: exit to quit)"; \
      PS1="(debug) $PS1" bash --noprofile --norc; exit $rc' ERR

# ëª¨ë“  ì¶œë ¥ ë¡œê·¸ë¡œ ì €ì¥ (í™”ë©´ì—ë„ ì¶œë ¥)
exec > >(tee -a "$LOG_FILE") 2>&1

# ë””ë²„ê·¸(ì›í•˜ë©´ ì£¼ì„ í•´ì œ)
# set -x


echo "== Bootstrap started $(date) =="


# Oneâ€‘stop automation script for provisioning AWS resources with Terraform
# and deploying the shoppingâ€‘mall application to an EKS cluster via a
# bastion host.  This script assumes you have valid AWS credentials
# configured on your local machine (via environment variables or the
# default AWS config files) and that you have a working SSH key for
# connecting to the bastion instance.  The bastion instance will
# perform container image builds and pushes, then apply the Kubernetes
# manifests to the newly created cluster.

# --------------------------------------------------------------------
# Configuration
#
# The following environment variables can be overridden to customise
# the behaviour of this script.  You can export them in your shell or
# define them in an env.sh file which will be sourced automatically
# when present.
#
# TF_DIR          â€“ path to the Terraform directory (default: ./terraform)
# APP_DIR         â€“ path to the application source directory containing
#                    the k8s manifests and Docker build contexts
# REGION          â€“ AWS region (default: ap-northeast-2)
# IMAGE_TAG       â€“ tag to apply to the built Docker images (default: latest)
# SSH_KEY         â€“ path to the private key for SSH into the bastion
# SSH_USER        â€“ user name to use for SSH (default: ec2-user)
# USE_ECR_SECRET  â€“ set to "true" to create a Kubernetes image pull
#                    secret and attach it to the service account
#
# DB_MASTER_USERNAME, DB_MASTER_PASSWORD, DB_NAME â€“ credentials for
# the RDS database.  These must match the values used in your
# terraform.tfvars.  They are used to build the SQLAlchemy URI for
# the backend service.
#
# JWT_SECRET_KEY  â€“ optional preâ€‘seeded JWT secret.  If omitted a
# random value will be generated by the remote script.
#
# FQDN            â€“ fully qualified domain name for the ingress host.
#
# You can set these variables in an env.sh file in the same directory
# as this script.  That file is ignored by git so you can store
# secrets there safely.  See env.sh.example for a starting point.
# --------------------------------------------------------------------

# Source userâ€‘defined environment variables if present
# ë™ì¼ ê²½ë¡œ ìƒì— env.sh íŒŒì¼ì´ ì¡´ì¬í•˜ë©´, ê·¸ íŒŒì¼ì„ í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ì— í¬í•¨ì‹œì¼œì„œ í™˜ê²½ ë³€ìˆ˜ë“¤ì„ ì„¤ì •í•¨
if [[ -f "$(dirname "$0")/env.sh" ]]; then
  # shellcheck disable=SC1090
 source "$(dirname "$0")/env.sh"
fi

# Apply defaults
# ì•„ë˜ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì • 
REGION=${REGION:-"ap-northeast-2"} 
TF_DIR=${TF_DIR:-"./terra"} # tfíŒŒì¼ ìœ„ì¹˜ 
APP_DIR=${APP_DIR:-"./bastion_scripts"} # bastionì— ì „ë‹¬í•  íŒŒì¼ ìœ„ì¹˜ 
IMAGE_TAG=${IMAGE_TAG:-"latest"}
SSH_USER=${SSH_USER:-"ec2-user"}
SSH_KEY=${SSH_KEY:-"./LetMeIn.pem"} # Bastion ì ‘ì†ì„ ìœ„í•œ SSH í‚¤ 
DB_MASTER_USERNAME=${DB_MASTER_USERNAME:-"admin"}
DB_MASTER_PASSWORD=${DB_MASTER_PASSWORD:-"passWord"}
DB_NAME=${DB_NAME:-"shopdb"}
FQDN=${FQDN:-"shop.gyowoon.shop"}
JWT_SECRET_KEY=${JWT_SECRET_KEY:-""}    # ì˜µì…˜. ë¹ˆ ê°’ì´ë©´ ìë™ìœ¼ë¡œ ìƒì„±



# Resolve required variables -> í•„ìˆ˜ ë³€ìˆ˜ í™•ì¸(SSH Key, DBê´€ë ¨ ë³€ìˆ˜)
## z ì˜µì…˜: ë³€ìˆ˜ê°€ ë¹„ì–´ìˆê±°ë‚˜, ì •ì˜ë˜ì§€ ì•Šì€ ê²½ìš° true ë°˜í™˜ 
if [[ -z "${SSH_KEY:-}" ]]; then
  echo "ERROR: SSH_KEY environment variable must be set to the path of your bastion SSH private key" >&2
  exit 1
fi
if [[ -z "${DB_MASTER_USERNAME:-}" || -z "${DB_MASTER_PASSWORD:-}" || -z "${DB_NAME:-}" ]]; then
  echo "ERROR: DB_MASTER_USERNAME, DB_MASTER_PASSWORD and DB_NAME must be set to match your terraform.tfvars" >&2
  exit 1
fi

# Ensure the SSH key exists
## f ì˜µì…˜: íŒŒì¼ì´ ì¡´ì¬í•˜ê³ , ì¼ë°˜ íŒŒì¼ì¸ ê²½ìš° true ë°˜í™˜
if [[ ! -f "$SSH_KEY" ]]; then
  echo "ERROR: SSH key file $SSH_KEY not found" >&2
  exit 1
fi

# Convenience function to print headings
heading() {
  echo
  echo "==================== $1 ====================="
}

# 1. Remove orphaned resources and apply Terraform configuration
heading "Cleaning up state and applying configuration"

# First remove the orphaned kubernetes_config_map from state
terraform -chdir="$TF_DIR" state rm module.bastion.kubernetes_config_map.aws_auth 2>/dev/null || true

# Check if bastion module exists in state
if terraform -chdir="$TF_DIR" state list | grep -q "module.bastion"; then
  heading "Destroying existing Bastion instance"
  terraform -chdir="$TF_DIR" destroy -target=module.bastion -auto-approve
else
  heading "No existing Bastion instance found"
fi

heading "Running terraform apply"
terraform -chdir="$TF_DIR" init -upgrade
terraform -chdir="$TF_DIR" apply -auto-approve

# 2. Retrieve outputs we need
## í…Œë¼í¼ ì‹¤í–‰ outputë“¤ì„ raw ë¬¸ìê°’ìœ¼ë¡œ, ë³€ìˆ˜í™”ì‹œí‚¤ê³  í„°ë¯¸ë„ë¡œ ì¶œë ¥ 
heading "Collecting terraform outputs"
CLUSTER_NAME=$(terraform -chdir="$TF_DIR" output -raw cluster_name)
BASTION_IP=$(terraform -chdir="$TF_DIR" output -raw bastion_public_ip)
RDS_ENDPOINT=$(terraform -chdir="$TF_DIR" output -raw rds_endpoint)
REDIS_ENDPOINT=$(terraform -chdir="$TF_DIR" output -raw redis_endpoint)

echo "Cluster name     : $CLUSTER_NAME"
echo "Bastion public IP: $BASTION_IP"
echo "RDS endpoint     : $RDS_ENDPOINT"
echo "Redis endpoint   : $REDIS_ENDPOINT"

# 3. Determine AWS account ID for ECR registry construction
## ECR ì ‘ì†ì„ ìœ„í•œ AWS ê³„ì • ID ì¡°íšŒ
ACCOUNT_ID=$("$AWS_CLI" sts get-caller-identity --query Account --output text)
ECR_REGISTRY="${ACCOUNT_ID}.dkr.ecr.${REGION}.amazonaws.com"
echo "AWS Account ID   : $ACCOUNT_ID"

# 4. Copy application artiafacts and prepare remote script
## rsyncë¥¼ ì´ìš©í•´ì„œ Bastionì— ì „ë‹¬í• , ë°°í¬ê°€ëŠ¥í•œ ë¹Œë“œìš© RAWíŒŒì¼(Front/BackEnd)/ì‚°ì¶œë¬¼/k8s Manifest(YAMLS)ë“¤ì„ ì˜ë¯¸í•¨
heading "Uploading application artefacts to bastion"

# The application directory is expected to contain unpacked folders named
# k8s, backend and frontend.  If these folders are missing we abort.

if [[ ! -d "$APP_DIR" ]]; then
  echo "ERROR: directory $APP_DIR/ not found.  Please ensure your app source directory contains the uncompressed folders." >&2
  exit 1
fi


# Copy the unpacked application folders to the bastion host.  We use rsync
# with --delete to ensure the remote directories exactly mirror the local
# ones.  The trailing slash on the source ensures that rsync copies the
# contents into the destination directory rather than creating a nested
# folder.
## Send some of mainfests(YAML) and RAW F/E & B/E Files from Local to Bastion 


SSH_OPTS="-o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null"
## -o StrictHostKeyChecking=no: SSHê°€ ì²˜ìŒ ì ‘ì†í•˜ëŠ” í˜¸ìŠ¤íŠ¸ì˜ í‚¤ë¥¼ ìë™ìœ¼ë¡œ ì‹ ë¢°í•˜ë„ë¡ ì„¤ì •í•¨
## -o UserKnownHostsFile=/dev/null: í˜¸ìŠ¤íŠ¸ í‚¤ë¥¼ ì €ì¥í•˜ì§€ ì•Šë„ë¡ ì„¤ì •í•¨(ë³´ì•ˆìƒ ìœ„í—˜í•  ìˆ˜ ìˆìŒ)

# verbose SSH ì—°ê²° ì‹œë„
#ssh -vvv -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null -i "$SSH_KEY" "$SSH_USER@$BASTION_IP" "whoami; pwd; ls -la ~/"


rsync -avz -e "ssh $SSH_OPTS -i $SSH_KEY" "$APP_DIR/" "${SSH_USER}@${BASTION_IP}:~/" >/dev/null

# 5. Write a file containing environment variables to the bastion.  When
# you SSH into the bastion you can source this file to reuse the
# Terraform outputs and other settings.  Note that sensitive values
# like DB credentials are included, so treat this file with care.
## Send some of tfstate Output from Local to Bastion 
heading "Copying environment variables to bastion"
cat > /tmp/bastion_env.sh <<EOF
export REGION=${REGION}
export CLUSTER_NAME=${CLUSTER_NAME}
export ACCOUNT_ID=${ACCOUNT_ID}
export IMAGE_TAG=${IMAGE_TAG}
export ECR_REGISTRY=${ECR_REGISTRY}
export RDS_ENDPOINT=${RDS_ENDPOINT}
export REDIS_ENDPOINT=${REDIS_ENDPOINT}
export DB_MASTER_USERNAME=${DB_MASTER_USERNAME}
export DB_MASTER_PASSWORD=${DB_MASTER_PASSWORD}
export DB_NAME=${DB_NAME}
export JWT_SECRET_KEY=${JWT_SECRET_KEY:-}
aws eks update-kubeconfig --region "$REGION" --name "$CLUSTER_NAME" --alias "$CLUSTER_NAME"

EOF
#scp -i "$SSH_KEY" /tmp/bastion_env.sh "${SSH_USER}@${BASTION_IP}:~/0_env.sh" >/dev/null
#ssh -i "$SSH_KEY" "${SSH_USER}@${BASTION_IP}" "chmod 600 ~/0_env.sh"

# scpë¡œ ì‹¤í–‰ ì‹œì ì— ìƒì„±ëœ í™˜ê²½ë³€ìˆ˜ ê´€ë ¨ íŒŒì¼ì„ Bastionìœ¼ë¡œ ì „ë‹¬
scp $SSH_OPTS -i "$SSH_KEY" /tmp/bastion_env.sh "${SSH_USER}@${BASTION_IP}:~/0_env.sh"

# sshë¡œ Bastionì— ì ‘ì†í•˜ì—¬, ì „ë‹¬ëœ í™˜ê²½ë³€ìˆ˜ ê´€ë ¨ íŒŒì¼ì˜ ê¶Œí•œì„ 600ìœ¼ë¡œ ë³€ê²½
ssh $SSH_OPTS -i "$SSH_KEY" "${SSH_USER}@${BASTION_IP}" "chmod 600 ~/0_env.sh"

## Bootstrap Finish Notice 
heading "Bootstrap completed"
echo "Terraform apply and file transfers are complete.  Please SSH into the bastion host (${BASTION_IP}) and source ~/env.sh to load the environment variables.  You can then run ~/remote_deploy.sh manually or execute commands interactively to deploy your application."
